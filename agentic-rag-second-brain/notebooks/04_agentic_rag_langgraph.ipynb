{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agentic RAG with LangGraph (timeframe drift fix)\n",
        "\n",
        "This notebook adds explicit control flow to fix timeframe drift: **rewrite → retrieve → grade → bounded retry → generate with citations + confidence**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d251b5c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config loaded.\n",
            "PROJECT_ROOT=C:\\Repos\\Intro-to-RAG-Agentic-RAG-2602\\agentic-rag-second-brain\n",
            "OPENAI_MODEL=gpt-4o-mini\n",
            "TOP_K=6, MAX_RETRIES=2, RECENCY_DAYS=365\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "def _find_project_root() -> Path:\n",
        "    cwd = Path.cwd().resolve()\n",
        "    for base in (cwd, *cwd.parents):\n",
        "        if (base / \"src\" / \"config.py\").exists():\n",
        "            return base\n",
        "        nested = base / \"agentic-rag-second-brain\"\n",
        "        if (nested / \"src\" / \"config.py\").exists():\n",
        "            return nested\n",
        "    raise RuntimeError(\"Could not locate project root containing src/config.py\")\n",
        "\n",
        "PROJECT_ROOT = _find_project_root()\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "os.chdir(PROJECT_ROOT)\n",
        "\n",
        "from src.config import settings\n",
        "from src.graph import build_agentic_rag_graph, run_agentic_rag\n",
        "from src.rag_baseline import baseline_rag_answer\n",
        "from src.retrieval import load_persisted_index\n",
        "\n",
        "load_dotenv()\n",
        "if not os.getenv('OPENAI_API_KEY'):\n",
        "    raise EnvironmentError('OPENAI_API_KEY is missing. Set it in your environment or .env file.')\n",
        "\n",
        "print('Config loaded.')\n",
        "print(f\"PROJECT_ROOT={PROJECT_ROOT}\")\n",
        "print(f\"OPENAI_MODEL={settings.openai_model}\")\n",
        "print(f\"TOP_K={settings.top_k}, MAX_RETRIES={settings.max_retries}, RECENCY_DAYS={settings.recency_days}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index loaded from data\\processed\\chroma\n"
          ]
        }
      ],
      "source": [
        "index_dir = Path(settings.chroma_dir)\n",
        "if not index_dir.exists() or not any(index_dir.iterdir()):\n",
        "    raise FileNotFoundError(\n",
        "        f'Persisted index not found at {index_dir}. Run notebooks/02_indexing_chroma_llamaindex.ipynb first.'\n",
        "    )\n",
        "\n",
        "index = load_persisted_index(chroma_dir=index_dir, embed_model=settings.embed_model)\n",
        "print(f'Index loaded from {index_dir}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline answer (Notebook 03 style):\n",
            "The recommended embedding model to use is EmbedPro-v2, as it has been shown to improve retrieval quality for nuanced queries, despite a significant cost increase compared to EmbedLite-v1. This change was made due to the need for better handling of semantically subtle questions that EmbedLite-v1 struggled with.\n",
            "Baseline citations:\n",
            "- {'doc_title': 'Embedding Model Decision Update: Quality Priority', 'doc_date': '2025-07-05', 'chunk_id': '1843528f9966ef38e563dc60ec056795eab0a0b1:7', 'source_path': 'C:\\\\Repos\\\\Intro-to-RAG-Agentic-RAG-2602\\\\agentic-rag-second-brain\\\\data\\\\raw\\\\notes\\\\2025-07-05-embedding-model-quality-shift.md'}\n",
            "- {'doc_title': 'Embedding Rollout Postmortem', 'doc_date': '2025-10-21', 'chunk_id': '3ce7ccdc6cae9be14a952f15d541a4f87c73ec51:11', 'source_path': 'C:\\\\Repos\\\\Intro-to-RAG-Agentic-RAG-2602\\\\agentic-rag-second-brain\\\\data\\\\raw\\\\notes\\\\2025-10-21-embedding-rollout-postmortem.md'}\n"
          ]
        }
      ],
      "source": [
        "DRIFT_QUERY = 'What embedding model should we use?'\n",
        "\n",
        "# Optional reminder of baseline behavior from Notebook 03\n",
        "baseline = baseline_rag_answer(\n",
        "    index=index,\n",
        "    query=DRIFT_QUERY,\n",
        "    top_k=int(settings.top_k),\n",
        "    model=settings.openai_model,\n",
        "    temperature=float(settings.temperature),\n",
        "    max_context_chars=int(settings.max_context_chars),\n",
        ")\n",
        "print('Baseline answer (Notebook 03 style):')\n",
        "print(baseline['answer'])\n",
        "print('Baseline citations:')\n",
        "for c in baseline['citations']:\n",
        "    print('-', c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision trace:\n",
            "- rewrite: What is the latest recommendation for which embedding model to use? Prefer latest notes by date.\n",
            "- retrieve: 627528ea8b8af5f59df5fae9b902a22869e8e53f:0|2025-01-10|Embedding Model Decision: Cost-First Default, aa23b701925fb16b6312fa7dc6f53474541c46fc:3|2025-03-18|Q1 Embedding Evaluation Notes, 1843528f9966ef38e563dc60ec056795eab0a0b1:7|2025-07-05|Embedding Model Decision Update: Quality Priority, 3ce7ccdc6cae9be14a952f15d541a4f87c73ec51:11|2025-10-21|Embedding Rollout Postmortem, 23d249bcab98910ef4133cf9ece7801e2b179a31:10|2025-10-02|Demo Retro: Internal Stakeholder Session, 20f6f8a9b43928b36d1bb1bb1d53b6391bf5eec0:9|2025-09-03|Chunking Strategy v2: Smaller Chunks + Overlap\n",
            "- grade: evidence_ok=True, confidence=high (recent_chunks=6, min_required=1, topic_match=True, conflict_signals=False)\n",
            "- continue: evidence_ok=True retry_count=0\n",
            "- generate: completed answer with citations\n",
            "\n",
            "Rewritten query:\n",
            "What is the latest recommendation for which embedding model to use? Prefer latest notes by date.\n",
            "\n",
            "Retrieved chunks (score | doc_date | doc_title | chunk_id):\n",
            "- 0.4278633546013658 | 2025-01-10 | Embedding Model Decision: Cost-First Default | 627528ea8b8af5f59df5fae9b902a22869e8e53f:0\n",
            "- 0.40433448526154775 | 2025-03-18 | Q1 Embedding Evaluation Notes | aa23b701925fb16b6312fa7dc6f53474541c46fc:3\n",
            "- 0.402619834199041 | 2025-07-05 | Embedding Model Decision Update: Quality Priority | 1843528f9966ef38e563dc60ec056795eab0a0b1:7\n",
            "- 0.3699358104662187 | 2025-10-21 | Embedding Rollout Postmortem | 3ce7ccdc6cae9be14a952f15d541a4f87c73ec51:11\n",
            "- 0.2907996740763794 | 2025-10-02 | Demo Retro: Internal Stakeholder Session | 23d249bcab98910ef4133cf9ece7801e2b179a31:10\n",
            "- 0.2875775633505184 | 2025-09-03 | Chunking Strategy v2: Smaller Chunks + Overlap | 20f6f8a9b43928b36d1bb1bb1d53b6391bf5eec0:9\n",
            "\n",
            "Grade + retries:\n",
            "evidence_ok=True, retry_count=0, confidence=high\n",
            "\n",
            "Final answer payload:\n",
            "{\n",
            "  \"answer\": \"The latest recommendation for embedding models is to use EmbedPro-v2 as the default. This change was made due to improved retrieval quality for semantically subtle questions, despite a higher cost compared to EmbedLite-v1. The decision also includes monitoring budget alerts weekly to manage costs effectively.\",\n",
            "  \"citations\": [\n",
            "    {\n",
            "      \"doc_title\": \"Embedding Model Decision Update: Quality Priority\",\n",
            "      \"doc_date\": \"2025-07-05\",\n",
            "      \"chunk_id\": \"1843528f9966ef38e563dc60ec056795eab0a0b1:7\",\n",
            "      \"source_path\": \"C:\\\\Repos\\\\Intro-to-RAG-Agentic-RAG-2602\\\\agentic-rag-second-brain\\\\data\\\\raw\\\\notes\\\\2025-07-05-embedding-model-quality-shift.md\"\n",
            "    },\n",
            "    {\n",
            "      \"doc_title\": \"Embedding Rollout Postmortem\",\n",
            "      \"doc_date\": \"2025-10-21\",\n",
            "      \"chunk_id\": \"3ce7ccdc6cae9be14a952f15d541a4f87c73ec51:11\",\n",
            "      \"source_path\": \"C:\\\\Repos\\\\Intro-to-RAG-Agentic-RAG-2602\\\\agentic-rag-second-brain\\\\data\\\\raw\\\\notes\\\\2025-10-21-embedding-rollout-postmortem.md\"\n",
            "    }\n",
            "  ],\n",
            "  \"confidence\": \"high\",\n",
            "  \"next_step\": \"\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "graph = build_agentic_rag_graph(\n",
        "    index=index,\n",
        "    openai_model=settings.openai_model,\n",
        "    temperature=float(settings.temperature),\n",
        "    top_k=int(settings.top_k),\n",
        "    max_context_chars=int(settings.max_context_chars),\n",
        "    max_retries=int(settings.max_retries),\n",
        "    recency_days=int(settings.recency_days),\n",
        "    evidence_min_recent_chunks=int(settings.evidence_min_recent_chunks),\n",
        "    use_llm_grader=settings.use_llm_grader == '1',\n",
        "    raw_notes_dir=settings.raw_notes_dir,\n",
        ")\n",
        "\n",
        "result = run_agentic_rag(graph, DRIFT_QUERY)\n",
        "\n",
        "print('Decision trace:')\n",
        "for step in result['decision_trace']:\n",
        "    print('-', step)\n",
        "\n",
        "print('\\nRewritten query:')\n",
        "print(result['rewritten_query'])\n",
        "\n",
        "print('\\nRetrieved chunks (score | doc_date | doc_title | chunk_id):')\n",
        "for chunk in result['retrieved_chunks']:\n",
        "    print(\n",
        "        f\"- {chunk['score']} | {chunk['doc_date']} | {chunk['doc_title']} | {chunk['chunk_id']}\"\n",
        "    )\n",
        "\n",
        "print('\\nGrade + retries:')\n",
        "print(f\"evidence_ok={result['evidence_ok']}, retry_count={result['retry_count']}, confidence={result['confidence']}\")\n",
        "\n",
        "print('\\nFinal answer payload:')\n",
        "print(json.dumps(result['final_answer'], indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What changed vs baseline?\n",
        "\n",
        "The baseline pipeline in Notebook 03 is retrieve → generate with no explicit evidence checks, so it can drift to stale recommendations.\n",
        "\n",
        "Notebook 04 adds explicit control flow with LangGraph:\n",
        "1. rewrite query for recency intent\n",
        "2. retrieve chunks\n",
        "3. grade evidence for recency + relevance\n",
        "4. bounded retry (`MAX_RETRIES`) if evidence is weak\n",
        "5. generate grounded answer with citations + confidence (+ optional clarifying next step when confidence is low).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "agentic-rag-second-brain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
