{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Timeframe drift dataset + LlamaIndex ingestion\n",
        "\n",
        "Create a deterministic markdown note corpus, ingest it with LlamaIndex, and preview timeframe drift."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from src.config import config\n",
        "from src.dataset import ensure_dataset_exists\n",
        "from src.ingestion import load_markdown_documents, chunk_documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "force_rebuild = False\n",
        "summary = ensure_dataset_exists(force_rebuild=force_rebuild)\n",
        "print('Notes created:', summary['num_notes'])\n",
        "print('Sample filenames:', summary['filenames'][:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rows = []\n",
        "for path in sorted(config.DATA_RAW_NOTES_DIR.glob('*.md')):\n",
        "    text = path.read_text(encoding='utf-8')\n",
        "    parts = text.split('---')\n",
        "    frontmatter = parts[1].strip().splitlines()\n",
        "    item = {'filename': path.name, 'title': '', 'date': '', 'tags': []}\n",
        "    i = 0\n",
        "    while i < len(frontmatter):\n",
        "        line = frontmatter[i]\n",
        "        if line.startswith('title:'):\n",
        "            item['title'] = line.split(':', 1)[1].strip()\n",
        "        elif line.startswith('date:'):\n",
        "            item['date'] = line.split(':', 1)[1].strip()\n",
        "        elif line.startswith('tags:'):\n",
        "            tags = []\n",
        "            i += 1\n",
        "            while i < len(frontmatter) and frontmatter[i].lstrip().startswith('-'):\n",
        "                tags.append(frontmatter[i].split('-', 1)[1].strip())\n",
        "                i += 1\n",
        "            item['tags'] = tags\n",
        "            continue\n",
        "        i += 1\n",
        "    rows.append(item)\n",
        "\n",
        "notes_df = pd.DataFrame(rows).sort_values('date').reset_index(drop=True)\n",
        "notes_df[['title', 'date', 'tags', 'filename']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "documents = load_markdown_documents(config.DATA_RAW_NOTES_DIR)\n",
        "nodes = chunk_documents(documents)\n",
        "print('Number of documents:', len(documents))\n",
        "print('Number of chunks/nodes:', len(nodes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for node in nodes[:3]:\n",
        "    md = node.metadata\n",
        "    print('-' * 80)\n",
        "    print('doc_title:', md.get('doc_title'))\n",
        "    print('doc_date:', md.get('doc_date'))\n",
        "    print('tags:', md.get('tags'))\n",
        "    print('source_path:', md.get('source_path'))\n",
        "    print('chunk_id:', md.get('chunk_id'))\n",
        "    print('chunk_text:', node.text[:300])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "keyword = 'embedding model'\n",
        "drift_rows = []\n",
        "for node in nodes:\n",
        "    text = node.text.lower()\n",
        "    title = str(node.metadata.get('doc_title', '')).lower()\n",
        "    if keyword in text or keyword in title:\n",
        "        drift_rows.append({\n",
        "            'doc_date': node.metadata.get('doc_date'),\n",
        "            'doc_title': node.metadata.get('doc_title'),\n",
        "            'tags': node.metadata.get('tags'),\n",
        "            'chunk_id': node.metadata.get('chunk_id'),\n",
        "            'preview': node.text[:180].replace('\\n', ' '),\n",
        "        })\n",
        "\n",
        "drift_df = pd.DataFrame(drift_rows).sort_values('doc_date').reset_index(drop=True)\n",
        "print('Drift preview for keyword:', keyword)\n",
        "drift_df\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
